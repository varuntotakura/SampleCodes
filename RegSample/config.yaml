# Data Configuration
data:
  input_file: "housing.csv"  # Now points to our downloaded dataset
  target_column: "target"
  test_size: 0.2
  random_state: 42
  synthetic_data:
    enable: false

# Mode Configuration
mode:
  use_inf_as_null: false
  handle_outliers: true

# Preprocessing Configuration
preprocessing:
  missing_values:
    strategy: "auto"
    custom_rules: {}
  scaling:
    method: "standard"
    target_range: [-1, 1]

# Feature Engineering
feature_engineering:
  enable: true
  methods:
    derived_features:
      enable: true
      operations:
        - name: "rooms_per_household"
          columns: ["AveRooms", "AveOccup"]
          operation: "ratio"
        - name: "bedrooms_ratio"
          columns: ["AveBedrms", "AveRooms"]
          operation: "ratio"
    interactions:
      enable: true
      feature_pairs: [["MedInc", "AveRooms"], ["Population", "AveOccup"]]
      interaction_type: "multiplication"  # Fixed: Added interaction_type
    pca:
      enable: true
      n_components: 5
    polynomial:
      enable: true
      degree: 2
      interaction_only: false

# Feature Selection
feature_selection:
  enable: true
  methods:
    - name: k_best
      enable: true
      params:
        k: 10
        score_func: f_regression
    - name: lasso
      enable: true
      params:
        alpha: [0.001, 0.01, 0.1, 1.0]
        threshold: 0.01
    - name: random_forest
      enable: true
      params:
        n_estimators: 100
        threshold: 0.01
    - name: vif
      enable: true
      params:
        threshold: 5.0
    - name: rfe
      enable: true
      params:
        n_features_to_select: 5
        step: 1

# Model Configuration
models:
  - name: 'xgboost'
    enable: true
    fixed_params:  # Parameters that don't need tuning
      objective: "reg:squarederror"
      nthread: -1
    params:  # Parameters to tune
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1, 0.3]
      n_estimators: [100, 200]
      subsample: [0.8, 1.0]
      colsample_bytree: [0.8, 1.0]
      min_child_weight: [1, 3, 5]

  - name: 'adaboost'
    enable: true
    params:
      n_estimators: [50, 100, 200]
      learning_rate: [0.01, 0.1, 0.5, 1.0]
      loss: ['linear', 'square', 'exponential']

  - name: 'linear'
    enable: true
    params:
      fit_intercept: [true, false]
      normalize: [true, false]
      copy_X: [true]
      n_jobs: [-1]
      positive: [false]

  - name: 'lasso'
    enable: True
    params:
      alpha: [0.001, 0.01, 0.1, 1.0]
      fit_intercept: [True]
      max_iter: [1000]
      tol: [0.0001]
      selection: ['cyclic']
      random_state: [42]

  - name: 'ridge'
    enable: True
    params:
      alpha: [0.001, 0.01, 0.1, 1.0]
      fit_intercept: [True]
      max_iter: [1000]
      tol: [0.001]
      solver: ['auto']
      random_state: [42]

  - name: 'elastic_net'
    enable: True
    params:
      alpha: [0.001, 0.01, 0.1, 1.0]
      l1_ratio: [0.1, 0.5, 0.7, 0.9]
      fit_intercept: [True]
      max_iter: [1000]
      tol: [0.0001]
      selection: ['cyclic']
      random_state: [42]

  - name: 'svr'
    enable: True
    params:
      C: [0.1, 1.0, 10.0]
      epsilon: [0.1, 0.2, 0.3]
      kernel: ['rbf', 'linear']
      gamma: ['scale', 'auto']
      tol: [0.001]
      max_iter: [1000]

  - name: 'random_forest'
    enable: True
    params:
      n_estimators: [100, 200, 500]
      max_depth: [null, 10, 20]
      min_samples_split: [2, 5]
      min_samples_leaf: [1, 2]
      max_features: ['auto', 'sqrt']
      bootstrap: [True]
      criterion: ['squared_error']
      max_leaf_nodes: [null]
      min_impurity_decrease: [0.0]
      warm_start: [False]
      n_jobs: [-1]
      random_state: [42]

  - name: 'gradient_boosting'
    enable: True
    params:
      n_estimators: [100, 200]
      learning_rate: [0.1]
      max_depth: [3, 5]
      min_samples_split: [2]
      min_samples_leaf: [1]
      subsample: [0.8]
      max_features: ['auto']
      criterion: ['friedman_mse']
      loss: ['squared_error']
      random_state: [42]

  - name: 'knn'
    enable: true
    params:
      n_neighbors: [3, 5, 7, 9]
      weights: ['uniform', 'distance']
      algorithm: ['auto']
      leaf_size: [20, 30]
      p: [1, 2]
      metric: ['minkowski']
      n_jobs: [-1]

# Hyperparameter Tuning
tuning:
  method: random  # 'random' or 'grid'
  cv_folds: 2  # Changed from 1 to 5
  n_iter: 2  # Increased from 2 to 10 for better random search
  scoring: neg_mean_squared_error

# Model Evaluation
evaluation:
  metrics:
    - 'mse'
    - 'rmse'
    - 'mae'
    - 'r2'
    - 'explained_variance'
  analysis:
    learning_curves: True
    validation_curves: True
    feature_importance: True
    prediction_error: True
    residuals: True
    outliers: True
    cross_validation: True
  plots:
    residuals: True
    learning_curves: True
    validation_curves: True
    feature_importance: True
    prediction_error: True

# Output Configuration
output:
  save_model: True
  results_path: results
  model_path: models
  plots_path: plots
  log_level: INFO

# Hardware Configuration
hardware:
  use_gpu: False
  n_jobs: -1  # -1 for using all available cores